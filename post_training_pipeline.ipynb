{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b97b08d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Complete post-training optimization pipeline for Binary Neural Networks (BNNs)\n",
    "with TALL evaluation and hardware deployment preparation.\n",
    "\n",
    "This pipeline includes:\n",
    "1. Baseline evaluation\n",
    "2. BatchNorm folding\n",
    "3. Bias constant clamping\n",
    "4. TALL parameter optimization\n",
    "5. Hardware export\n",
    "\n",
    "Usage:\n",
    "    python post_training_pipeline.py --model-path bnn_deep_best.pth --model-type deep\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "\n",
    "from BNN_model import (\n",
    "    BinaryMLP, TALLClassifier, \n",
    "    build_cam4_deep, build_cam4_shallow,\n",
    "    apply_post_training_optimization,\n",
    "    export_hardware_weights,\n",
    "    create_hardware_checkpoint\n",
    ")\n",
    "\n",
    "from evaluate_mnist import evaluate_model\n",
    "\n",
    "def get_mnist_test_loader(batch_size=1000, data_dir='./data'):\n",
    "    \"\"\"Get MNIST test data loader\"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root=data_dir, train=False, transform=transform, download=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2\n",
    "    )\n",
    "    \n",
    "    return test_loader\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac980ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading MNIST test set...\n",
      "Creating Deep BNN model...\n",
      "Loading model from bnn_deep_best.pth...\n",
      "Model trained for 130 epochs\n",
      "Best test accuracy(popcount last layer output): 97.38%\n"
     ]
    }
   ],
   "source": [
    "# Setup device\n",
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load test data\n",
    "print(\"Loading MNIST test set...\")\n",
    "test_loader = get_mnist_test_loader(batch_size=1000, data_dir=\"./data\")\n",
    "\n",
    "model_type = \"deep\"  # Change to \"deep\" for deep model\n",
    "def load_bnn_model(model_type, device, thresholds = [0,0,0]):\n",
    "    # Create and load model based on model_type\n",
    "    if model_type == \"shallow\":\n",
    "        print(f\"Creating Shallow BNN model...\")\n",
    "        model = build_cam4_shallow(num_classes=10)\n",
    "        model_path = \"bnn_shallow_best.pth\"\n",
    "    elif model_type == \"deep\":\n",
    "        print(f\"Creating Deep BNN model...\")\n",
    "        model = build_cam4_deep(num_classes=10, thresholds=thresholds)\n",
    "        model_path = \"bnn_deep_best.pth\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_type: {model_type}\")\n",
    "\n",
    "    print(f\"Loading model from {model_path}...\")\n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "\n",
    "    print(f\"Model trained for {checkpoint.get('epoch', 'unknown')} epochs\")\n",
    "    print(f\"Best test accuracy(popcount last layer output): {checkpoint.get('best_acc', 'unknown'):.2f}%\")\n",
    "    return model, checkpoint\n",
    "\n",
    "model, checkpoint = load_bnn_model(model_type, device)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e743a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy with last layer binary output: 52.17%\n"
     ]
    }
   ],
   "source": [
    "accuracy, _ = evaluate_model(model, test_loader, device, verbose=False)\n",
    "print(f\"Baseline test accuracy with last layer binary output: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0229716c",
   "metadata": {},
   "source": [
    "# threshold expiriment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d0b8a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Deep BNN model...\n",
      "Loading model from bnn_deep_best.pth...\n",
      "Model trained for 130 epochs\n",
      "Best test accuracy(popcount last layer output): 97.38%\n"
     ]
    }
   ],
   "source": [
    "model, checkpoint = load_bnn_model(model_type, device, thresholds=[0.1, 0.1, 0.1])\n",
    "accuracy, _ = evaluate_model(model, test_loader, device, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa97b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
